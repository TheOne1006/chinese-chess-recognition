{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../\"\n",
    "# 数据集的目录\n",
    "dataset_dir_train = os.path.join(root_dir, \"data/cchess_multi_label_layout\", \"train\")\n",
    "dataset_dir_val = os.path.join(root_dir, \"data/cchess_multi_label_layout\", \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历数据集\n",
    "def get_all_files(dataset_dir):\n",
    "    file_list = os.listdir(dataset_dir)\n",
    "\n",
    "    sorted_file_list = sorted(file_list)\n",
    "    \n",
    "    target_files = []\n",
    "\n",
    "    for file in sorted_file_list:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            # ann\n",
    "            ann_file = file.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "            if not os.path.exists(os.path.join(dataset_dir, ann_file)):\n",
    "                print(f\"ann_file not exists: {ann_file}\")\n",
    "                continue\n",
    "            target_files.append(os.path.join(dataset_dir, file))\n",
    "            \n",
    "    return target_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_files = get_all_files(dataset_dir_train)\n",
    "all_files.extend(get_all_files(dataset_dir_val))\n",
    "print(len(all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除 fifityone, 重新创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"chess_multi_label\"\n",
    "\n",
    "fo.delete_dataset(project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:48:58.239797520 [W:onnxruntime:, session_state.cc:1136 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2025-03-10 14:48:58.239811528 [W:onnxruntime:, session_state.cc:1138 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from onnx_classifier.full_classifier import FULL_CLASSIFIER_ONNX\n",
    "\n",
    "full_classifier = FULL_CLASSIFIER_ONNX(\n",
    "    model_path=os.path.join('..', \"work_dirs/deploy_0315/cchess_reg.onnx\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21285 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21285/21285 [07:33<00:00, 46.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# all_files\n",
    "import tqdm\n",
    "\n",
    "all_samples = []\n",
    "\n",
    "start_center_x = 50\n",
    "start_center_y = 50\n",
    "\n",
    "image_width = 450\n",
    "image_height = 500\n",
    "\n",
    "# 图片原尺寸 width = 450, height = 500\n",
    "\n",
    "item_width = (image_width - 50) / 9\n",
    "item_height = (image_height - 50) / 10\n",
    "\n",
    "\n",
    "batch_size = 32  # 设置批处理大小\n",
    "\n",
    "# 创建数据集\n",
    "dataset = fo.Dataset(\"chess_multi_label\")\n",
    "\n",
    "# 遍历所有图片文件\n",
    "for img_path in tqdm.tqdm(all_files):\n",
    "    # 获取对应的标注文件路径\n",
    "    ann_path = img_path.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "\n",
    "    if not os.path.exists(ann_path):\n",
    "        print(f\"ann_path not exists: {ann_path}\")\n",
    "        continue\n",
    "    \n",
    "    annotation = ''\n",
    "    with open(ann_path, 'r', encoding='utf-8') as f:\n",
    "        annotation = f.read()\n",
    "\n",
    "    _, short_labels, confidence_10x9, _ = full_classifier.pred(img_path)\n",
    "\n",
    "\n",
    "    annotation = annotation.strip()\n",
    "    # annotation_arr_10_9 为 10 行 9 列的二维数组\n",
    "    # ['.C....r..', '....a....', '...kba...', 'p.p.p.pCp', '..b.....c', '.cP.n.P..', 'P.......P', 'BR..Ba...', '....KR...', '...N.a.N.']\n",
    "    annotation_10_rows = [item for item in annotation.split(\"\\n\")]\n",
    "    # 将 annotation_10_rows 转换成为 10 行 9 列的二维数组\n",
    "    annotation_arr_10_9 = [list(item) for item in annotation_10_rows]\n",
    "\n",
    "\n",
    "    detections = []\n",
    "\n",
    "\n",
    "    for row_index, row in enumerate(annotation_arr_10_9):\n",
    "        for col_index, col in enumerate(row):\n",
    "            if col != '.':\n",
    "                detections.append(fo.Detection(\n",
    "                    label=col,\n",
    "                    bounding_box=[\n",
    "                        (start_center_x + col_index * item_width - item_width / 2) / image_width, \n",
    "                        (start_center_y + row_index * item_height - item_height / 2) / image_height, \n",
    "                        item_width / image_width, \n",
    "                        item_height / image_height\n",
    "                    ]\n",
    "                ))\n",
    "\n",
    "    pred_detections = []\n",
    "    for row_index, row in enumerate(short_labels):\n",
    "        for col_index, col in enumerate(row):\n",
    "            if col != '.':\n",
    "                pred_detections.append(fo.Detection(\n",
    "                    label=col,\n",
    "                    confidence=confidence_10x9[row_index][col_index],\n",
    "                    bounding_box=[\n",
    "                        (start_center_x + col_index * item_width - item_width / 2) / image_width, \n",
    "                        (start_center_y + row_index * item_height - item_height / 2) / image_height, \n",
    "                        item_width / image_width, \n",
    "                        item_height / image_height\n",
    "                    ]\n",
    "                ))\n",
    "\n",
    "    diff_detections = []\n",
    "    padding = 10\n",
    "    for row_index in range(10):\n",
    "        for col_index in range(9):\n",
    "            ann_label = annotation_arr_10_9[row_index][col_index]\n",
    "            pred_label = short_labels[row_index][col_index]\n",
    "\n",
    "            # 忽略 x 和 .\n",
    "            if ann_label == 'x' and pred_label == '.':\n",
    "                continue\n",
    "\n",
    "            if ann_label == '.' and pred_label == 'x':\n",
    "                continue\n",
    "\n",
    "            # 不一致才展示\n",
    "            if ann_label != pred_label:\n",
    "                diff_detections.append(fo.Detection(\n",
    "                    label=f\"{ann_label} -> {pred_label}\",\n",
    "                    bounding_box=[\n",
    "                        (start_center_x + col_index * item_width - item_width / 2 + padding) / image_width, \n",
    "                        (start_center_y + row_index * item_height - item_height / 2 + padding) / image_height, \n",
    "                        (item_width - padding * 2) / image_width, \n",
    "                        (item_height - padding * 2) / image_height\n",
    "                    ]\n",
    "                ))\n",
    "\n",
    "    base_name = os.path.basename(img_path)\n",
    "\n",
    "    tag=\"js_v2\"\n",
    "\n",
    "    # 判断 base_name 是否以 js_v2_ 开头\n",
    "    if not base_name.startswith(\"js_v2_\"):\n",
    "\n",
    "        if \"_\" in base_name:\n",
    "            base_name_arr = base_name.split(\"_\")\n",
    "        else:\n",
    "            base_name_arr = base_name.split(\"-\")\n",
    "        \n",
    "        tag = base_name_arr[0]\n",
    "    \n",
    "    sample = fo.Sample(filepath=img_path, tags=[tag])\n",
    "        # 添加多标签分类信息\n",
    "    sample['ground_truth'] = fo.Detections(\n",
    "        detections=detections\n",
    "    )\n",
    "    sample['predictions'] = fo.Detections(\n",
    "        detections=pred_detections\n",
    "    )\n",
    "    sample['diff'] = fo.Detections(\n",
    "        detections=diff_detections\n",
    "    )\n",
    "    # all_samples.append(sample)\n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "\n",
    "\n",
    "# dataset.default_config = \n",
    "#     draw_config=draw_config\n",
    "# )\n",
    "\n",
    "# 保存数据集\n",
    "dataset.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建各种 view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找 文件以 'js' 开头\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "# 修正: 含有 js_v2_ 的 文件, 且存在 diff 标签\n",
    "js_diff_view = dataset.match({\n",
    "    \"filepath\": {\"$regex\": \".*js_v2_.*\"},\n",
    "})\n",
    "\n",
    "js_diff_view = js_diff_view.match({\n",
    "    \"diff.detections\": {\"$not\": {\"$size\": 0}}  # 检测结果数组非空\n",
    "})\n",
    "# 保存 view\n",
    "js_diff_view.save(\"js_diff_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(js_diff_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_game_diff_view = dataset.match({\n",
    "    \"filepath\": {\"$regex\": \".*mock_game_.*\"},\n",
    "})\n",
    "\n",
    "mock_game_diff_view = mock_game_diff_view.match({\n",
    "    \"diff.detections\": {\"$not\": {\"$size\": 0}}  # 检测结果数组非空\n",
    "})\n",
    "# 保存 view\n",
    "mock_game_diff_view.save(\"mock_game_diff_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_view(\"mock_game_diff_view\", mock_game_diff_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1475"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mock_game_diff_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 不包含 mock_game_ 的 view\n",
    "all_diff_view = dataset.match({\n",
    "    \"filepath\": {\"$not\": {\"$regex\": \".*mock_game_.*\"}},\n",
    "})\n",
    "\n",
    "all_diff_view = all_diff_view.match({\n",
    "    \"diff.detections\": {\"$not\": {\"$size\": 0}}  # 检测结果数组非空\n",
    "})\n",
    "# 保存 view\n",
    "all_diff_view.save(\"all_diff_view\")\n",
    "dataset.save_view(\"all_diff_view\", all_diff_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_diff_view)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cchess_reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
